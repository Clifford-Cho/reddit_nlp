{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246a0370",
   "metadata": {},
   "source": [
    "# Reddit Analysis using Pushshift API\n",
    "\n",
    "## Part 1: Data Scraping\n",
    "- [Background](#Background)\n",
    "- [Problem Statement](#Problem-Statement)\n",
    "- [Data Scraping](#Data-Scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ef63c",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Reddit is a website that dubs itself itself as the \"Front Page of the Internet\" and functions as hybrid between a news service and social media. The website is divided into subreddits, miniature communities that cover topics that range from overarching (news, science, music, etc.) to incredibly specific (AskNYC, dogecoin, siberianhusky). In these subreddits, users can make posts and up-vote or down-vote it. With enough popularity, a post can make it to the popular section of reddit where it will be seen by anyone that browses the website. This creates a self-functioning advertisement cycle that allows users to join communities they find interesting. The foundation of each post is the title, body text (contains links and images as well), and comments. In the background, users can also send and receive private messages.\n",
    "\n",
    "In this project, we will be analyzing data from two subreddits:\n",
    "\n",
    "1. [r/TalesFromRetail](https://www.reddit.com/r/TalesFromRetail/) (640k members): This subreddit talks about experiences from employees working in retail. The posts are mainly negative and largely refers to \"Karens\", people who are known for being entitled and demanding to others in a public environment.\n",
    "\n",
    "2.  [r/raisedbynarcissists](https://www.reddit.com/r/raisedbynarcissists/) (714k members): This subreddit is a support group for people who had abusive and toxic parental figures. Posts range from personal history to questions and discussions regarding a user's personal life."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66e7e5",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The aforementioned subreddits were chosen because both of them focus on negative experiences with specific people in their lives. The two subreddits also have a similar amount of activity. However, there is a large difference between the two as TalesFromRetail deals with one time interactions with strangers while raisedbynarcissists deals with longer and intimate history between family members.\n",
    "\n",
    "While Karens are known for being openly obnoxious, narcissists can be soft-spoken and manipulative.This juxtaposition between public/private abusers led to a question if there were any personality similarities between the two types of people. This project has two main goals. The first is to utilize NLP methods to see what types of vocabulary can be seen in both subreddits. The second is to use classification models in order to see if the subreddit origin of a post can be found. Do Karens and narcissistic parents have any overlap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1a182",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489a0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts for /r/raisedbynarcissists\n",
    "def get_posts1():\n",
    "    post_num = range(0, 1000, 50)\n",
    "    base_url = 'https://api.pushshift.io/reddit/search/'\n",
    "\n",
    "    for x in post_num:\n",
    "        if x == 0:\n",
    "            params = {\n",
    "                'subreddit': 'raisedbynarcissists',\n",
    "                'size': 50\n",
    "            }\n",
    "            res = requests.get(base_url + 'submission/', params = params)\n",
    "            data = res.json()\n",
    "            posts = pd.DataFrame(data['data'])\n",
    "            earliest = posts['created_utc'].min()\n",
    "\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            new_params = {\n",
    "                'subreddit': 'raisedbynarcissists',\n",
    "                'size': 50,\n",
    "                'before': earliest\n",
    "            }\n",
    "            new_res = requests.get(base_url + 'submission/', params = new_params)\n",
    "            new_data = new_res.json()\n",
    "            new_df = pd.DataFrame(new_data['data'])\n",
    "            earliest = new_df['created_utc'].min()\n",
    "\n",
    "            posts = pd.concat([posts, new_df], ignore_index = True)\n",
    "\n",
    "            time.sleep(2)\n",
    "    df1 = posts\n",
    "    df1.to_csv('../data/narcissists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c4a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts for /r/TalesFromRetail\n",
    "def get_posts2():\n",
    "    post_num = range(0, 4500, 50) # 4500 posts gathered due to abundance of [removed] posts\n",
    "    base_url = 'https://api.pushshift.io/reddit/search/'\n",
    "\n",
    "    for x in post_num:\n",
    "        if x == 0:\n",
    "            params = {\n",
    "                'subreddit': 'TalesFromRetail',\n",
    "                'size': 50\n",
    "            }\n",
    "            res = requests.get(base_url + 'submission/', params = params)\n",
    "            data = res.json()\n",
    "            posts = pd.DataFrame(data['data'])\n",
    "            earliest = posts['created_utc'].min()\n",
    "\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            new_params = {\n",
    "                'subreddit': 'TalesFromRetail',\n",
    "                'size': 50,\n",
    "                'before': earliest\n",
    "            }\n",
    "            new_res = requests.get(base_url + 'submission/', params = new_params)\n",
    "            new_data = new_res.json()\n",
    "            new_df = pd.DataFrame(new_data['data'])\n",
    "            earliest = new_df['created_utc'].min()\n",
    "\n",
    "            posts = pd.concat([posts, new_df], ignore_index = True)\n",
    "\n",
    "            time.sleep(2)\n",
    "    df2 = posts\n",
    "    df2.to_csv('../data/retail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79bca370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preliminary inspection on possibly useful columns\n",
    "def insp():\n",
    "    for col in df1.columns:\n",
    "        try:\n",
    "            if df1.drop_duplicates(subset = col).shape[0] > 100:\n",
    "                print(f'Unique in {col} is {df1.drop_duplicates(subset = col).shape[0]}')\n",
    "        except:\n",
    "            print(f'{col} is unhashable') # TypeError: unhashable type: 'list'\n",
    "\n",
    "    # Preliminary inspection on possibly useful columns\n",
    "    for col in df2.columns:\n",
    "        try:\n",
    "            if df2.drop_duplicates(subset = col).shape[0] > 100:\n",
    "                print(f'Unique in {col} is {df2.drop_duplicates(subset = col).shape[0]}')\n",
    "        except:\n",
    "            print(f'{col} is unhashable') # TypeError: unhashable type: 'list'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
